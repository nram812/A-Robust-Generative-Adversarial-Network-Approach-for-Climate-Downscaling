{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import json\n",
    "# changed activation function to hyperbolic tangent\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "from dask.diagnostics import ProgressBar\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "os.chdir(r'/nesi/project/niwa00018/ML_downscaling_CCAM/A-Robust-Generative-Adversarial-Network-Approach-for-Climate-Downscaling')\n",
    "\n",
    "# Create an experiment with your api key\n",
    "sys.path.append(r'/nesi/project/niwa00018/ML_downscaling_CCAM/A-Robust-Generative-Adversarial-Network-Approach-for-Climate-Downscaling')\n",
    "from src.layers import *\n",
    "from src.models import *\n",
    "from src.gan import *\n",
    "from ops.model_inference.src_eval_inference import *\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import json\n",
    "# changed activation function to hyperbolic tangent\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# TODO LOAD DEFAULT CONFIG VARIABLES\n",
    "n_members = 10\n",
    "model_dir = '/nesi/project/niwa00018/ML_downscaling_CCAM/A-Robust-Generative-Adversarial-Network-Approach-for-Climate-Downscaling/models'\n",
    "filepath = '/nesi/project/niwa00018/ML_downscaling_CCAM/training_GAN/ancil_fields/ERA5_eval_ccam_12km.198110_NZ_Invariant.nc'\n",
    "output_dir = '/nesi/project/niwa00018/ML_downscaling_CCAM/A-Robust-Generative-Adversarial-Network-Approach-for-Climate-Downscaling/outputs/Reviewer'\n",
    "\n",
    "# default config_file \n",
    "config_file = r'/nesi/project/niwa00018/ML_downscaling_CCAM/A-Robust-Generative-Adversarial-Network-Approach-for-Climate-Downscaling/models/Reviewer_Historical_ACCESS-CM2_0.0001/config_info.json'\n",
    "with open(config_file) as f:\n",
    "    config = json.load(f)\n",
    "historical_period = slice(\"1985\",\"2014\")\n",
    "future_period = slice(\"2015\",\"2035\")\n",
    "config[\"train_x\"] =\"/nesi/project/niwa00018/ML_downscaling_CCAM/multi-variate-gan/inputs/predictor_fields/predictor_fields_hist_ssp370_merged_updated.nc\"\n",
    "config[\"train_y\"] = \"/nesi/project/niwa00018/ML_downscaling_CCAM/multi-variate-gan/inputs/target_fields/target_fields_hist_ssp370_concat.nc\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'orog' ()>\n",
      "array(1733.36035156) <xarray.DataArray 'he' ()>\n",
      "array(1157.46264648) <xarray.DataArray 'vegt' ()>\n",
      "array(17.00000763)\n"
     ]
    }
   ],
   "source": [
    "stacked_X, y, vegt, orog, he = preprocess_input_data(config, match_index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "experiments_no_iten = ['Reviewer_Historical_ACCESS-CM2_0.01',\n",
    "               'Reviewer_Historical_ACCESS-CM2_0.0001',\n",
    "               'Reviewer_Historical_ACCESS-CM2_0.001',\n",
    "               'Reviewer_Historical_ACCESS-CM2_0.0025',\n",
    "               'Reviewer_Historical_ACCESS-CM2_0.005',\n",
    "               'Reviewer_Historical_ACCESS-CM2_0.01',\n",
    "               'Reviewer_Historical_ACCESS-CM2_0.1',\n",
    "               ]\n",
    "\n",
    "experiments_iten = ['Reviewer_Historical_Intensity_Max_ACCESS-CM2_0.01',\n",
    "               'Reviewer_Historical_Intensity_Max_ACCESS-CM2_0.0001',\n",
    "               'Reviewer_Historical_Intensity_Max_ACCESS-CM2_0.001',\n",
    "               'Reviewer_Historical_Intensity_Max_ACCESS-CM2_0.0025',\n",
    "               'Reviewer_Historical_Intensity_Max_ACCESS-CM2_0.005',\n",
    "               'Reviewer_Historical_Intensity_Max_ACCESS-CM2_0.01',\n",
    "               'Reviewer_Historical_Intensity_Max_ACCESS-CM2_0.1',\n",
    "               ]\n",
    "\n",
    "\n",
    "\n",
    "timeslice = slice(\"1986\", \"2014\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_experiments(experiments, epoch_list, model_dir,\n",
    "                    input_predictors, common_times, output_shape, orog, he, vegt, n_members, batch_size=64,\n",
    "                    fixed_unet=True, gcm = None):\n",
    "    \"\"\"\n",
    "    Runs inference on some predictor fields in/ out-of-sample\n",
    "\n",
    "\n",
    "    experiments: list of experiment names in the model_dir folder\n",
    "    input_predictors: stacked netcdf with dims (time, lat, lon, channel) and normalized data\n",
    "    common_times: common_times between output_shape data and input_predictors\n",
    "    output_shape: a netcdf (y_true) that is the same shape as the output prediction, it contains the time metadata\n",
    "    orog, he, vegt: auxiliary files from ccam\n",
    "    n_member: the number of ensemble members\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # if the epoch list is only a float convert to a list\n",
    "    if isinstance(epoch_list, int):\n",
    "        epoch_list = [epoch_list] * len(experiments)\n",
    "\n",
    "    # creating empty lists to save outputs            \n",
    "    dsets = []\n",
    "    lambda_var = []\n",
    "    for i, experiment in enumerate(experiments):\n",
    "        gan, unet, lambdas = load_model_cascade(experiment, None, model_dir, load_unet=True)\n",
    "        if i == 0:\n",
    "            # first instance is always a unet model\n",
    "            lambdas = 0.0\n",
    "            preds = xr.concat([predict_parallel_resid(gan, unet,\n",
    "                                                        input_predictors.sel( GCM =gcm).transpose('time','lat','lon','channel').sel(time = common_times).values,\n",
    "                                                        output_shape.sel(time=common_times),\n",
    "                                                        batch_size, orog.values, he.values, vegt.values, model_type='unet')\n",
    "                                for i in range(n_members)],\n",
    "                                dim=\"member\")\n",
    "            \n",
    "        else:\n",
    "                # do not change lambdas value otherwise\n",
    "            lambdas = lambdas\n",
    "            preds = xr.concat([predict_parallel_resid(gan, unet,\n",
    "                                                        input_predictors.sel( GCM =gcm).transpose('time','lat','lon','channel').sel(time = common_times).values,\n",
    "                                                        output_shape.sel(time=common_times),\n",
    "                                                        batch_size, orog.values, he.values, vegt.values, model_type='GAN')\n",
    "                                for i in range(n_members)],\n",
    "                                dim=\"member\")\n",
    "        lambda_var.append(lambdas)\n",
    "        dsets.append(preds)\n",
    "        # finish the experiment and concatenate the data\n",
    "    dsets = xr.concat(dsets, dim=\"experiment\")\n",
    "    dsets['experiment'] = (('experiment'), lambda_var)\n",
    "    dsets = dsets.reindex(experiment=sorted(dsets.experiment.values))\n",
    "    return dsets\n",
    "\n",
    "try:\n",
    "    y = y.isel(GCM =0)[['pr']]\n",
    "except:\n",
    "    y =y[['pr']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max orog: 1733.3603515625, Max he: 1157.462646484375, Max vegt: 17.00000762939453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  29%|██▉       | 48/165 [00:35<01:25,  1.37batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-39f14e413366>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvegt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_normalize_topography_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     output_prediction = run_experiments(experiments_no_iten, [], model_dir,\n\u001b[0m\u001b[1;32m     11\u001b[0m                                         \u001b[0mstacked_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon_time_perfect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvegt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_members\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                         batch_size=64, gcm = model)\n",
      "\u001b[0;32m<ipython-input-13-4e4e4c7d5ead>\u001b[0m in \u001b[0;36mrun_experiments\u001b[0;34m(experiments, epoch_list, model_dir, input_predictors, common_times, output_shape, orog, he, vegt, n_members, batch_size, fixed_unet, gcm)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# first instance is always a unet model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mlambdas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             preds = xr.concat([predict_parallel_resid(gan, unet,\n\u001b[0m\u001b[1;32m     30\u001b[0m                                                         \u001b[0minput_predictors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mGCM\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mgcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lon'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'channel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                                                         \u001b[0moutput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommon_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-4e4e4c7d5ead>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# first instance is always a unet model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mlambdas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             preds = xr.concat([predict_parallel_resid(gan, unet,\n\u001b[0m\u001b[1;32m     30\u001b[0m                                                         \u001b[0minput_predictors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mGCM\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mgcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lon'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'channel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                                                         \u001b[0moutput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommon_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nesi/project/niwa00018/ML_downscaling_CCAM/A-Robust-Generative-Adversarial-Network-Approach-for-Climate-Downscaling/ops/model_inference/src_eval_inference.py\u001b[0m in \u001b[0;36mpredict_parallel_resid\u001b[0;34m(model, unet, inputs, output_shape, batch_size, orog_vector, he_vector, vegt_vector, model_type)\u001b[0m\n\u001b[1;32m    184\u001b[0m                                             model_type)\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mdset\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update the progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for model in list(stacked_X.GCM.values):\n",
    "    common_time_perfect = stacked_X.sel(time=timeslice).time.to_index().intersection(y.time.to_index())\n",
    "    output_shape = create_output(stacked_X.sel(time = common_time_perfect), y.sel(time = common_time_perfect))\n",
    "    output_shape.pr.values = output_shape.pr.values * 0.0\n",
    "    \n",
    "    # ensuring that the data is cleared\n",
    "    # load the imperfect_conditions\n",
    "    vegt, orog, he = load_and_normalize_topography_data(filepath)\n",
    "\n",
    "    output_prediction = run_experiments(experiments_no_iten, [], model_dir,\n",
    "                                        stacked_X, common_time_perfect, output_shape, orog, he, vegt, n_members,\n",
    "                                        batch_size=64, gcm = model)\n",
    "    if not os.path.exists(  f'{output_dir}/No_Constraint/'):\n",
    "        os.makedirs( f'{output_dir}/No_Constraint/')\n",
    "\n",
    "    if not os.path.exists(  f'{output_dir}/Intensity_Constrained'):\n",
    "        os.makedirs( f'{output_dir}/Intensity_Constrained')\n",
    "\n",
    "    output_prediction.to_netcdf(\n",
    "        f'{output_dir}/No_Constraint/{model}_unconstrained_hist_1986_2005_perfect_framework.nc')\n",
    "\n",
    "\n",
    "    # output_prediction = run_experiments(experiments_iten, [], model_dir,\n",
    "    #                                     stacked_X, common_time_perfect, output_shape, orog, he, vegt, n_members,\n",
    "    #                                     batch_size=64, gcm = model)\n",
    "    # output_prediction.to_netcdf(\n",
    "    #     f'{output_dir}/Intensity_Constrained/{model}_IC_hist_1986_2005_perfect_framework.nc')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My_env-V2",
   "language": "python",
   "name": "nellys_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
